{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TaXGrnOtHGi"
      },
      "source": [
        "# Assignment 8 - k-Nearest Neighbors (kNNs)\n",
        "(20 points)\n",
        "\n",
        "### Add your name(s) and EIDs below\n",
        "- Student Name: Shruthi Garla\n",
        "- Student UT EID: sg54464\n",
        "- Partner Name:\n",
        "- Partner UT EID:\n",
        "\n",
        "\n",
        "# k-Nearest Neighbors\n",
        "For this assignment, we are going explore one new classification technique: k nearest neighbors.\n",
        "\n",
        "We are using a different version of the Melbourne housing data set from earlier in the semester, split into training and testing sets for you. Our goal is to predict the housing type as one of three possible categories:\n",
        "\n",
        "  - 'h' house\n",
        "  - 'u' duplex\n",
        "  - 't' townhouse\n",
        "\n",
        "At the end of this homework, you will understand how to build and use a kNN model, and improve your data cleaning and data preparation skills."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k5avkIR9tHGj"
      },
      "outputs": [],
      "source": [
        "# These are the libraries you will use for this assignment.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import calendar\n",
        "from datetime import datetime\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rj_H5PKJtHGk",
        "outputId": "9ac92ef5-db8e-4200-f056-d58230937f5a"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'melb_data_train.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start off by loading the training dataset.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_melb \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmelb_data_train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_melb\n",
            "File \u001b[0;32m~/CS329E/myenv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/CS329E/myenv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m~/CS329E/myenv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/CS329E/myenv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[0;32m~/CS329E/myenv/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'melb_data_train.csv'"
          ]
        }
      ],
      "source": [
        "# Start off by loading the training dataset.\n",
        "df_melb = pd.read_csv('melb_data_train.csv')\n",
        "df_melb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rrfI4Q-tHGk"
      },
      "source": [
        "## Q1\n",
        "\n",
        "**Fix our \"Date\" column to be numeric**: If we inspect our dataframe `df_melb` using the `dtypes` property, we see that the column `Date` is an `object`.  However, we think this column might contain useful information, so your goal is to convert it to [Unix time](https://en.wikipedia.org/wiki/Unix_time).\n",
        "\n",
        "Unix time is the number of secconds since a fixed time known as the \"Unix epoch\", which is midnight on January 1st, 1970. For example, the Unix time for March 10th, 2023 is 1,678,474,369 seconds.\n",
        "\n",
        "- **Use only the libraries imported above** imported libraries to create a new column `UnixTime`.\n",
        "    - Be careful, the date strings in the file might have some non-uniform formatting that you have to fix first.  \n",
        "- Print out the min and max epoch time to check your work.  \n",
        "- Drop the original `Date` column.\n",
        "\n",
        "The Python [reference for time](https://docs.python.org/3/library/time.html) can help you with your conversion to Unix time.\n",
        "\n",
        "(**3 points**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQQY0h0YtHGk",
        "outputId": "bf98ab26-22ae-4510-acaa-94f5c1e8dab0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Rooms             int64\n",
              "Type             object\n",
              "Price             int64\n",
              "Date             object\n",
              "Distance        float64\n",
              "Postcode          int64\n",
              "Bathroom          int64\n",
              "Car             float64\n",
              "Landsize          int64\n",
              "BuildingArea    float64\n",
              "YearBuilt       float64\n",
              "dtype: object"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# For reference, here are the data types of each column.\n",
        "df_melb.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3UErKBetHGl"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ru76NMy2tHGl",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def standardize_date(date_string):\n",
        "    \"\"\"Standardize a date string to a standard format.\n",
        "\n",
        "    Rules:\n",
        "    - You can assume the input string is of the form day/month/year.\n",
        "    - Fixed date strings should be of the form DD/MM/YYYY. If a day is\n",
        "      one digit, append zeros.\n",
        "    - If the input string's year is two digits (e.g. 02), assume\n",
        "      the year is in the 2000s (e.g. 2002).\n",
        "    \"\"\"\n",
        "    day, month, year = date_string.split(\"/\")\n",
        "\n",
        "    # Ensure day and month are two digits\n",
        "    day = day.zfill(2)\n",
        "    month = month.zfill(2)\n",
        "\n",
        "    # Convert two-digit year to four-digit year\n",
        "    if len(year) == 2:\n",
        "        year = \"20\" + year\n",
        "    fixed_date_string = f\"{day}/{month}/{year}\"\n",
        "    return fixed_date_string\n",
        "\n",
        "def replace_date_with_unix(df):\n",
        "    \"\"\"Given a Melbourne dataset dataframe, replace the Date column\n",
        "    with a UnixTime column.\n",
        "\n",
        "    Hint: Call standardize_date within this function.\n",
        "    \"\"\"\n",
        "    df['Date'] = df['Date'].apply(standardize_date)\n",
        "\n",
        "    # Convert to Unix timestamp\n",
        "    df['UnixTime'] = df['Date'].apply(lambda x: int(time.mktime(datetime.strptime(x, \"%d/%m/%Y\").timetuple())))\n",
        "\n",
        "    # Drop the Date column\n",
        "    df = df.drop(columns=['Date'])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ly1dWLFvtHGl",
        "outputId": "29169781-202c-4033-cff5-b53e8014d997",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min UnixTime: 1454565600\n",
            "Max UnixTime: 1506142800\n"
          ]
        }
      ],
      "source": [
        "df_melb_q1 = replace_date_with_unix(df_melb)\n",
        "\n",
        "# Print the cleaned UnixTime values.\n",
        "print('Min UnixTime:', df_melb_q1['UnixTime'].min())\n",
        "print('Max UnixTime:', df_melb_q1['UnixTime'].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COGZklLptHGl"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "## Q2\n",
        "\n",
        "**Use imputation to fill in missing values**: kNN doesn't work when some attributes are not present, so we must fill in all the missing values in `df_melb` with something. As a simple estimate, we will fill in missing values with the **mean** of that value/column.\n",
        "\n",
        "What we're trying to classify ('h'ome/'d'u'plex/'t'ownhouse), also knonw as the **target**, is store in the `Type` column. We define a variable `target_col` which lets you automatically infer which column is the target. During imputation, we should skip this target column.\n",
        "\n",
        "- Use `df_melb_q1`, i.e. the result from Q1.\n",
        "- Save the mean of each column in a dictionary `dict_imputation`. Keys are an attribute's column name, and values are that attribute's mean.\n",
        "- Use `dict_imputation` to imputate the missing values in `df_melb_q1`.\n",
        "- Store the imputated dataframe in `df_melb_q2`.\n",
        "\n",
        "(**3 points**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW_R6YmVtHGl"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PksqsBvftHGm",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def build_imputation_dict(df, target_col):\n",
        "    \"\"\"Collect the mean values of each column, excluding NaN values\n",
        "    and the target column.\n",
        "    \"\"\"\n",
        "    dict_imputation = {}\n",
        "\n",
        "    # Get the mean value of each column, excluding the target column\n",
        "    for col in df.columns:\n",
        "        if col != target_col:\n",
        "            dict_imputation[col] = df[col].mean(skipna=True)\n",
        "    return dict_imputation\n",
        "\n",
        "def imputate(df, dict_imputation, target_col):\n",
        "    \"\"\"Imputate a dataframe, replacing missing values with those\n",
        "    given in dict_imputation. Do not imputate target_col.\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    for col, value in dict_imputation.items():\n",
        "        if col in df.columns and col != target_col:\n",
        "            df[col].fillna(value, inplace=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWjRs87EtHGm",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the target column as a string\n",
        "target_col = \"Type\"\n",
        "\n",
        "# Collect imputation values\n",
        "dict_imputation = build_imputation_dict(df_melb_q1, target_col)\n",
        "\n",
        "# Imputate the dataframe\n",
        "df_melb_q2 = imputate(df_melb_q1, dict_imputation, target_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4VqVbsjtHGm",
        "outputId": "263f67b6-83fc-45f6-f320-045de695de19",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Rooms': 2.710769230769231,\n",
              " 'Price': 941972.2953846154,\n",
              " 'Distance': 10.206256410256408,\n",
              " 'Postcode': 3110.873846153846,\n",
              " 'Bathroom': 1.4543589743589744,\n",
              " 'Car': 1.4938398357289528,\n",
              " 'Landsize': 514.2184615384615,\n",
              " 'BuildingArea': 131.379476861167,\n",
              " 'YearBuilt': 1971.0204429301534,\n",
              " 'UnixTime': 1485054996.9230769}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check your results\n",
        "dict_imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUXjj6b0tHGm",
        "outputId": "4ccdb0d4-84a0-4d29-d822-873024124aa5",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rooms</th>\n",
              "      <th>Type</th>\n",
              "      <th>Price</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Postcode</th>\n",
              "      <th>Bathroom</th>\n",
              "      <th>Car</th>\n",
              "      <th>Landsize</th>\n",
              "      <th>BuildingArea</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>UnixTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>t</td>\n",
              "      <td>732000</td>\n",
              "      <td>5.6</td>\n",
              "      <td>3101</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>904</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>1980.000000</td>\n",
              "      <td>1469509200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>h</td>\n",
              "      <td>1001000</td>\n",
              "      <td>12.6</td>\n",
              "      <td>3020</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>879</td>\n",
              "      <td>131.379477</td>\n",
              "      <td>1971.020443</td>\n",
              "      <td>1488607200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>u</td>\n",
              "      <td>605000</td>\n",
              "      <td>7.4</td>\n",
              "      <td>3185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>722</td>\n",
              "      <td>131.379477</td>\n",
              "      <td>1970.000000</td>\n",
              "      <td>1462597200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>h</td>\n",
              "      <td>757500</td>\n",
              "      <td>18.8</td>\n",
              "      <td>3170</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>145</td>\n",
              "      <td>131.379477</td>\n",
              "      <td>1971.020443</td>\n",
              "      <td>1497675600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>h</td>\n",
              "      <td>721000</td>\n",
              "      <td>17.9</td>\n",
              "      <td>3082</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>603</td>\n",
              "      <td>131.379477</td>\n",
              "      <td>1971.020443</td>\n",
              "      <td>1505538000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rooms Type    Price  Distance  Postcode  Bathroom  Car  Landsize  \\\n",
              "0      3    t   732000       5.6      3101         1  1.0       904   \n",
              "1      3    h  1001000      12.6      3020         1  5.0       879   \n",
              "2      2    u   605000       7.4      3185         1  1.0       722   \n",
              "3      3    h   757500      18.8      3170         2  1.0       145   \n",
              "4      4    h   721000      17.9      3082         2  2.0       603   \n",
              "\n",
              "   BuildingArea    YearBuilt    UnixTime  \n",
              "0    110.000000  1980.000000  1469509200  \n",
              "1    131.379477  1971.020443  1488607200  \n",
              "2    131.379477  1970.000000  1462597200  \n",
              "3    131.379477  1971.020443  1497675600  \n",
              "4    131.379477  1971.020443  1505538000  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check your results\n",
        "df_melb_q2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0f_wGhWtHGm"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "## Q3\n",
        "\n",
        "**Normalize all attributes to be between [0,1]**: Normalize all the attribute columns in `df_melb_q2` so they have a value between zero and one (inclusive).\n",
        "\n",
        "To do this, we will build a dictionary `dict_normalize`, with column names for keys and (min, max) tuples for values, which are the min (resp. max) value found in the dataframe for that column. Just like in Q2, we do not normalize the target column.\n",
        "\n",
        "After creating `dict_normalize`, we will use it to normalize each column and generate a new dataframe, `df_melb_q3`. The resulting dataframe is now your model that you can use to classify new data points.\n",
        "\n",
        "- Use `df_melb_q2`, i.e. the result from Q2.\n",
        "- Save the minimum and maximum values of each column in a dictionary `dict_normalize`. Keys are an attribute's column name, and values are a (min, amx) tuple for that column,\n",
        "- Use `dict_normalize` to normalize the missing values in `df_melb_q2`.\n",
        "- Store the imputated dataframe in `df_melb_q3`.\n",
        "\n",
        "(**3 points**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LgEPn6utHGm"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFW2o6JntHGm",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def build_normalization_dict(df, target_col):\n",
        "    \"\"\"Collect the (min, max) values of each column, except the\n",
        "    target column.\n",
        "    \"\"\"\n",
        "    dict_normalize = {}\n",
        "\n",
        "    # Get the min and max values of each column, excluding the target column\n",
        "    for col in df.columns:\n",
        "        if col != target_col:\n",
        "            dict_normalize[col] = (df[col].min(skipna=True), df[col].max(skipna=True))\n",
        "\n",
        "    return dict_normalize\n",
        "\n",
        "def normalize(df, dict_normalize, target_col):\n",
        "    \"\"\"Normalize a dataframe, setting all values to the range [0, 1]\n",
        "    using (min, max) values in dict_normalize. Do not normalize target_col.\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    for col, (min_val, max_val) in dict_normalize.items():\n",
        "        if col in df.columns and col != target_col:\n",
        "            df[col] = (df[col] - min_val) / (max_val - min_val)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sxoBPR5tHGm",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the target column as a string\n",
        "target_col = \"Type\"\n",
        "\n",
        "# Collect normalization values\n",
        "dict_normalize = build_normalization_dict(df_melb_q2, target_col)\n",
        "\n",
        "# Normalize the dataframe\n",
        "df_melb_q3 = normalize(df_melb_q2, dict_normalize, target_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJaTEovCtHGm",
        "outputId": "c2c056ca-3aef-4f08-e09d-771477aed7b5",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Rooms': (1, 7),\n",
              " 'Price': (210000, 5020000),\n",
              " 'Distance': (0.7, 47.3),\n",
              " 'Postcode': (3000, 3810),\n",
              " 'Bathroom': (0, 5),\n",
              " 'Car': (0.0, 8.0),\n",
              " 'Landsize': (0, 41400),\n",
              " 'BuildingArea': (0.0, 3558.0),\n",
              " 'YearBuilt': (1850.0, 2016.0),\n",
              " 'UnixTime': (1454565600, 1506142800)}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check your results\n",
        "dict_normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCc3wyzFtHGm",
        "outputId": "e0497a08-5b0e-4340-f8d7-ef7c02be8022",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rooms</th>\n",
              "      <th>Type</th>\n",
              "      <th>Price</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Postcode</th>\n",
              "      <th>Bathroom</th>\n",
              "      <th>Car</th>\n",
              "      <th>Landsize</th>\n",
              "      <th>BuildingArea</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>UnixTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>t</td>\n",
              "      <td>0.108524</td>\n",
              "      <td>0.105150</td>\n",
              "      <td>0.124691</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.021836</td>\n",
              "      <td>0.030916</td>\n",
              "      <td>0.783133</td>\n",
              "      <td>0.289733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>h</td>\n",
              "      <td>0.164449</td>\n",
              "      <td>0.255365</td>\n",
              "      <td>0.024691</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.021232</td>\n",
              "      <td>0.036925</td>\n",
              "      <td>0.729039</td>\n",
              "      <td>0.660013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>u</td>\n",
              "      <td>0.082121</td>\n",
              "      <td>0.143777</td>\n",
              "      <td>0.228395</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.017440</td>\n",
              "      <td>0.036925</td>\n",
              "      <td>0.722892</td>\n",
              "      <td>0.155720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>h</td>\n",
              "      <td>0.113825</td>\n",
              "      <td>0.388412</td>\n",
              "      <td>0.209877</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.003502</td>\n",
              "      <td>0.036925</td>\n",
              "      <td>0.729039</td>\n",
              "      <td>0.835834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>h</td>\n",
              "      <td>0.106237</td>\n",
              "      <td>0.369099</td>\n",
              "      <td>0.101235</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.014565</td>\n",
              "      <td>0.036925</td>\n",
              "      <td>0.729039</td>\n",
              "      <td>0.988274</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Rooms Type     Price  Distance  Postcode  Bathroom    Car  Landsize  \\\n",
              "0  0.333333    t  0.108524  0.105150  0.124691       0.2  0.125  0.021836   \n",
              "1  0.333333    h  0.164449  0.255365  0.024691       0.2  0.625  0.021232   \n",
              "2  0.166667    u  0.082121  0.143777  0.228395       0.2  0.125  0.017440   \n",
              "3  0.333333    h  0.113825  0.388412  0.209877       0.4  0.125  0.003502   \n",
              "4  0.500000    h  0.106237  0.369099  0.101235       0.4  0.250  0.014565   \n",
              "\n",
              "   BuildingArea  YearBuilt  UnixTime  \n",
              "0      0.030916   0.783133  0.289733  \n",
              "1      0.036925   0.729039  0.660013  \n",
              "2      0.036925   0.722892  0.155720  \n",
              "3      0.036925   0.729039  0.835834  \n",
              "4      0.036925   0.729039  0.988274  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check your results\n",
        "df_melb_q3.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acLLnx-4tHGm"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "## Q4\n",
        "\n",
        "**Prepare the test data**: Load in `melb_data_test.csv` and repeat the steps in Q1, Q2, and Q3 (unix time, imputation, and normalization).\n",
        "\n",
        "(**1 point**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWy5Rmf8tHGm"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dlu2XF2tHGm",
        "outputId": "1039a4c9-6a28-4ff2-d666-0a23a5d7f8f2"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "DataFrame constructor not properly called!",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16796\\1196064378.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_melb_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'melb_data_test.csv'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Replace with actual test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Clean the dates, add unix time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_melb_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreplace_date_with_unix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_melb_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    837\u001b[0m                 )\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# For data is scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DataFrame constructor not properly called!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: DataFrame constructor not properly called!"
          ]
        }
      ],
      "source": [
        "df_melb_test = pd.DataFrame()  # Replace with actual test data\n",
        "\n",
        "# Clean the dates, add unix time\n",
        "df_melb_test = replace_date_with_unix(df_melb_test)\n",
        "\n",
        "# Imputate the dataframe\n",
        "target_col = \"Type\"  # Replace with actual target column name\n",
        "dict_imputation_test = build_imputation_dict(df_melb_test, target_col)\n",
        "df_melb_test = imputate(df_melb_test, dict_imputation_test, target_col)\n",
        "\n",
        "# Normalize the dataframe\n",
        "dict_normalize_test = build_normalization_dict(df_melb_test, target_col)\n",
        "df_melb_test = normalize(df_melb_test, dict_normalize_test, target_col)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL0wGvHZtHGn",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Load the test dataframe\n",
        "df_melb_test = ...\n",
        "\n",
        "# Clean the dates, add unix time\n",
        "df_melb_test = replace_date_with_unix(df_melb_test)\n",
        "\n",
        "# Imputate the dataframe\n",
        "target_col = ...\n",
        "dict_imputation_test = ...\n",
        "df_melb_test = ...\n",
        "\n",
        "# Normalize the dataframe\n",
        "dict_normalize_test = ...\n",
        "df_melb_test = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWtNx-AJtHGn",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Check your results\n",
        "df_melb_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMaVwRX_tHGn"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "## Q5\n",
        "\n",
        "**Write the kNN classifier function**: Your function, `predict_knn` will take in the following four parameters:\n",
        "- Training dataframe `df_train`\n",
        "- Hyperparameter `k`\n",
        "- Testing sample `test_sample` (one row of the DataFrame, we can generate it using `iloc` or `iterrows`).\n",
        "- Target column string `target_col`, which defines the variable we want to predict.\n",
        "\n",
        "It will predict which class `test_sample` belongs to, based on the `k` nearest neighbors to the sample.\n",
        "\n",
        "- We assume `df_train` is normalized/imputated, contains all attributes, and also contains the target column.\n",
        "- Likewise, we assume `test_sample` is normalized/imputated and contains all attributes. (But, it does not have to have the target column).\n",
        "\n",
        "*Hint*: To find the distance between the test sample and any element of the training dataset, you may use the [L2 norm function from numpy](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html).\n",
        "\n",
        "(**5 points**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DDMVHB6tHGn"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEPIyIOUtHGn",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def predict_knn(df_train: pd.DataFrame, k: int,\n",
        "                test_sample: pd.Series, target_col: str):\n",
        "    \"\"\"Use the k-nearest neighbors algorithm to predict the class of a test-sample,\n",
        "    given a training set.\n",
        "\n",
        "    Parameters:\n",
        "        df_train:    DataFrame of training samples\n",
        "        k:           Number of neighbors to consider\n",
        "        test_sample: Single evaluation sample\n",
        "        target_col:  Name of the target variable (column)\n",
        "\n",
        "    Returns:\n",
        "        prediction: Predicted class of the test sample using kNN.\n",
        "    \"\"\"\n",
        "    ...\n",
        "    prediction = ...\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wvt0xD9_tHGn"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "## Q6\n",
        "\n",
        "**Compute the accuracy using different k values**: For each value of $k$ in the set $\\{1,3,13,25,50,100\\}$, compute the kNN prediction for each oberservation in the test set, and the overall accuracy of the classifier.  Plot the accuracy as a function of $k$.\n",
        "\n",
        "- Use your imputed, normalize training dataframe (`df_melb_q3`).\n",
        "- Use your imputed, normalized testing dataframe (`df_melb_test`).\n",
        "- Have an outer loop over the k-values, and an inner loop computing the prediction for each testing sample under that k-value.\n",
        "\n",
        "Which value of $k$ would you choose? Why?\n",
        "\n",
        "(This can take a while to run; probably at least 5-10 minutes.)\n",
        "\n",
        "(**5 points - 3 for implementation, 1 for plot, 1 for description**).\n",
        "\n",
        "(**This question will be manually graded.**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp39HT21tHGn"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsOVzpaitHGn",
        "tags": [
          "otter_ignore"
        ]
      },
      "outputs": [],
      "source": [
        "# Sweep over the k-values. Place your accuracies for each k-value in acc_k.\n",
        "poss_k = [1, 3, 13, 25, 50, 100]\n",
        "acc_k = []\n",
        "\n",
        "# Your code goes below.\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3BKltEotHGn",
        "tags": [
          "otter_ignore"
        ]
      },
      "outputs": [],
      "source": [
        "# Plot your accuracies for each k-value.\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G27Inw0tHGn"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (myenv)",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "otter": {
      "OK_FORMAT": true,
      "assignment_name": "329e_HW08",
      "tests": {
        "q1": {
          "name": "q1",
          "points": 3,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q2": {
          "name": "q2",
          "points": 3,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q3": {
          "name": "q3",
          "points": 3,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q4": {
          "name": "q4",
          "points": 1,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q5": {
          "name": "q5",
          "points": 5,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        }
      }
    },
    "vscode": {
      "interpreter": {
        "hash": "05642a42904bc69a6f3fb292ea6dbf0463ee768c41640775e87375f7653a91c5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
